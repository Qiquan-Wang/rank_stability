{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application in Lung Tumour Application\n",
    "\n",
    "In this application, we follow the following steps:\n",
    "1. Convert MRIs to binary masks, volumes and sample point cloud from the tumour surface\n",
    "2. Construct bi-parameter filtration and compute corresponding rank invariant\n",
    "3. Classification using KNN and MBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modeule\n",
    "import pylidc as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import csv\n",
    "# set working directory\n",
    "workdir = \"/home/qw817/Desktop/Lung_TDA_application\"\n",
    "import os\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "os.chdir(workdir)\n",
    "sys.path.insert(0, os.path.join(workdir, \"Functions\"))\n",
    "\n",
    "# Handling dicom images\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# Persistent homology and topological feature extraction\n",
    "import TDAfeatures as tf\n",
    "from ripser import ripser\n",
    "from persim import plot_diagrams\n",
    "\n",
    "# training classifier\n",
    "import skfda\n",
    "from skfda.ml.classification import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from skfda.representation.grid import FDataGrid\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import statistics\n",
    "from skfda.exploratory.depth import ModifiedBandDepth\n",
    "from skfda.ml.classification import MaximumDepthClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import diagnosis\n",
    "df = pd.read_csv('Diagnosis.csv', sep = ',') \n",
    "diagnosis = np.asarray(df) \n",
    "full_classes = diagnosis[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Convert MRIs into samples of points from the tumour surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "sizes = []\n",
    "num = 0\n",
    "all_masks = []\n",
    "all_pc =[]\n",
    "for i in diagnosis[:,0]:\n",
    "    # if annotation available generate binary masks and point clouds\n",
    "    if len(pl.query(pl.Scan).filter(pl.Scan.patient_id == i).first().annotations)!=0:\n",
    "        # identify annotation\n",
    "        ann = pl.query(pl.Annotation).join(pl.Scan)\\\n",
    "                .filter(pl.Scan.patient_id == i).first()\n",
    "        # generate binary mask\n",
    "        mask = ann.boolean_mask()\n",
    "        all_masks.append(mask)\n",
    "        # concate mask into one large matrix\n",
    "        test1 = np.concatenate([mask[:,:,j] for j in range(mask.shape[2])], axis=0)\n",
    "        # save np array as csv\n",
    "        # np.savetxt(\"masks/\"+i+\"_mask.csv\", test1, delimiter=\",\")\n",
    "        # save id\n",
    "        ids.append(i)\n",
    "        # save mask shape\n",
    "        sizes.append(mask.shape)\n",
    "\n",
    "        # generate pc\n",
    "        vol = tf.read_dcm(\"dcm/\"+i[-4:])\n",
    "        verts, faces = tf.mesh_from_lesion(vol, mask)\n",
    "        all_pc.append(verts)\n",
    "        # save point clouds\n",
    "        #np.savetxt(\"point_clouds/\"+i+\"_pc.csv\", verts, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample for point clouds larger than 1000\n",
    "small_pc =[]\n",
    "for i in range(len(ids)):\n",
    "    current = all_pc[i]\n",
    "    if current.shape[0]>1000:\n",
    "        # randomly shuffle data\n",
    "        np.random.shuffle(current)\n",
    "        current = current[:1000,:]\n",
    "        small_pc.append(current)\n",
    "    else:\n",
    "        small_pc.append(current)\n",
    "    # save point clouds\n",
    "    # np.savetxt(\"small_point_clouds/pc_\"+ids[i][-4:]+\".txt\", current, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Construct bi-parameter filtration and corresponding rank invariant\n",
    "The bi-filtrations include:\n",
    "- Degree-rips filtration\n",
    "- H-rips filtration\n",
    "- X-rips filtration\n",
    "- Y-rips filtration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first can compute rank invariants with degree-rips filtration without adding new filtration values to the data\n",
    "degree_rips_rank_invariants = []\n",
    "for i in ids:\n",
    "    # compute bi-parameter using rivet    \n",
    "    cmd = \"/home/qw817/rivet/rivet_console /home/qw817/Desktop/Lung_TDA_application/small_point_clouds/pc_\"+i[-4:]+\".txt /home/qw817/Desktop/Lung_TDA_application/rivet_outputs/rivet\"+i[-4:]+\".rivet --datatype points --homology 0 --xbins 20 --ybins 20\"\n",
    "    os.popen(cmd).read().split('\\n')\n",
    "    # convert the rivert file to rank invariants\n",
    "    with open(\"rivet_outputs/rivet\"+i[-4:]+\".rivet\", 'rb') as f:\n",
    "        computed_data = f.read()\n",
    "    degree_rips_rank_invariants.append(rank_function(computed_data, grid_size=20, fixed_bounds=None, use_weights=False, normalize=False, minimum_rank=0))\n",
    "# convert to and save as matrix\n",
    "degree_rips_rank_invariants_mat = np.array(degree_rips_rank_invariants)\n",
    "# np.savetxt(\"computed_rank_invariants_degree_rips.csv\", np.array(degree_rips_rank_invariants), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The other three filtrations requires construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include second filtration - height/z parameter\n",
    "n = len(ids)\n",
    "for i in range(n):\n",
    "    pid = ids[i]\n",
    "    ppc = small_pc[i]\n",
    "    \n",
    "    # write to file\n",
    "    file_name = \"small_point_cloud_height_filtration/h_ptcl_\"+pid[-4:]+\".txt\"\n",
    "    f = open(file_name, \"w\")\n",
    "    f.write(\"--datatype points_fn\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\",\".join(map(str, ppc[:,2])))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    for j in range(ppc.shape[0]):\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\",\".join(map(str, ppc[j,:])))\n",
    "    \n",
    "    f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute rivet file and rank invariant\n",
    "h_rips_rank_invariants = []\n",
    "for i in ids:\n",
    "    # compute rivet file\n",
    "    cmd = \"/home/qw817/rivet/rivet_console /home/qw817/Desktop/Lung_TDA_application/small_point_cloud_height_filtration/h_ptcl_\"+i[-4:]+\".txt /home/qw817/Desktop/Lung_TDA_application/height_rivet/h_pc\"+i[-4:]+\".rivet --xbins 20 --ybins 20\"\n",
    "    os.popen(cmd).read().split('\\n')\n",
    "    # convert the rivert file to rank invariants\n",
    "    with open(\"height_rivet/h_pc\"+i[-4:]+\".rivet\", 'rb') as f:\n",
    "        computed_data = f.read()\n",
    "    h_rips_rank_invariants.append(rank_function(computed_data, grid_size=20, fixed_bounds=None, use_weights=False, normalize=False, minimum_rank=0))\n",
    "# convert to and save as matrix\n",
    "h_rips_rank_invariants_mat = np.array(h_rips_rank_invariants)\n",
    "# np.savetxt(\"computed_rank_invariants_height.csv\", np.array(h_rips_rank_invariants), delimiter=',')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include second filtration - x parameter\n",
    "n = len(ids)\n",
    "for i in range(n):\n",
    "    pid = ids[i]\n",
    "    ppc = small_pc[i]\n",
    "    \n",
    "    # write to file\n",
    "    file_name = \"x_pc/pc_\"+pid[-4:]+\".txt\"\n",
    "    f = open(file_name, \"w\")\n",
    "    f.write(\"--datatype points_fn\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\",\".join(map(str, ppc[:,0])))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    for j in range(ppc.shape[0]):\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\",\".join(map(str, ppc[j,:])))\n",
    "    \n",
    "    f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute rivet file and rank invariant\n",
    "x_rips_rank_invariants = []\n",
    "for i in ids:\n",
    "    # compute rivet file\n",
    "    cmd = \"/home/qw817/rivet/rivet_console /home/qw817/Desktop/Lung_TDA_application/x_pc/pc_\"+i[-4:]+\".txt /home/qw817/Desktop/Lung_TDA_application/x_rivet/x_pc\"+i[-4:]+\".rivet --xbins 20 --ybins 20\"\n",
    "    os.popen(cmd).read().split('\\n')\n",
    "    # convert the rivert file to rank invariants\n",
    "    with open(\"height_rivet/x_pc\"+i[-4:]+\".rivet\", 'rb') as f:\n",
    "        computed_data = f.read()\n",
    "    x_rips_rank_invariants.append(rank_function(computed_data, grid_size=20, fixed_bounds=None, use_weights=False, normalize=False, minimum_rank=0))\n",
    "# convert to and save as matrix\n",
    "x_rips_rank_invariants_mat = np.array(x_rips_rank_invariants)\n",
    "# np.savetxt(\"computed_rank_invariants_x.csv\", np.array(x_rips_rank_invariants), delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include second filtration - y parameter\n",
    "n = len(ids)\n",
    "for i in range(n):\n",
    "    pid = ids[i]\n",
    "    ppc = small_pc[i]\n",
    "    \n",
    "    # write to file\n",
    "    file_name = \"y_pc/pc_\"+pid[-4:]+\".txt\"\n",
    "    f = open(file_name, \"w\")\n",
    "    f.write(\"--datatype points_fn\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\",\".join(map(str, ppc[:,1])))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    for j in range(ppc.shape[0]):\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\",\".join(map(str, ppc[j,:])))\n",
    "    \n",
    "    f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute rivet file and rank invariant\n",
    "y_rips_rank_invariants = []\n",
    "for i in ids:\n",
    "    # compute rivet file\n",
    "    cmd = \"/home/qw817/rivet/rivet_console /home/qw817/Desktop/Lung_TDA_application/y_pc/pc_\"+i[-4:]+\".txt /home/qw817/Desktop/Lung_TDA_application/y_rivet/y_pc\"+i[-4:]+\".rivet --xbins 20 --ybins 20\"\n",
    "    os.popen(cmd).read().split('\\n')\n",
    "    # convert the rivert file to rank invariants\n",
    "    with open(\"height_rivet/y_pc\"+i[-4:]+\".rivet\", 'rb') as f:\n",
    "        computed_data = f.read()\n",
    "    y_rips_rank_invariants.append(rank_function(computed_data, grid_size=20, fixed_bounds=None, use_weights=False, normalize=False, minimum_rank=0))\n",
    "# convert to and save as matrix\n",
    "y_rips_rank_invariants_mat = np.array(y_rips_rank_invariants)\n",
    "# np.savetxt(\"computed_rank_invariants_y.csv\", np.array(y_rips_rank_invariants), delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Train classifiers\n",
    "- k-NN classifier\n",
    "- MBD classifer\n",
    "\n",
    "Import Meta data to find which contains contrasting material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import meta data\n",
    "meta = pd.read_csv(\"Meta.csv\")\n",
    "# contruct a dictionary of whether an image contained contrasting material\n",
    "contrast_dict = {}\n",
    "for i in range(meta.shape[0]):\n",
    "    contrast_dict[meta.to_numpy()[i,0][10:14]]=meta.to_numpy()[i,10]\n",
    "\n",
    "# find indices for which the tumours are benign or malignant\n",
    "benign_index = np.where(full_classes == 1)[0]\n",
    "malignant_index = np.where(full_classes == 2)[0]\n",
    "# and those with and without contrast\n",
    "benign_index_contrast = [i for i in benign_index if contrast_dict[ids[i][-4:]]==\"Y\"]\n",
    "malignant_index_contrast = [i for i in malignant_index if contrast_dict[ids[i][-4:]]==\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join indexes together\n",
    "primary_index_wcontrast = benign_index_contrast + malignant_index_contrast\n",
    "primary_index_no_contrast = benign_index.tolist() + malignant_index.tolist()\n",
    "# labels\n",
    "labels_wcontrast = [0 for i in range(len(benign_index_contrast))] + [1 for i in range(len(malignant_index_contrast))]\n",
    "labels_no_contrast = [0 for i in range(len(benign_index.tolist()))] + [1 for i in range(len(malignant_index.tolist()))]\n",
    "# contrast ranks\n",
    "dranks_wc = d_ranks[primary_index_wcontrast,:]\n",
    "hranks_wc = h_ranks[primary_index_wcontrast,:]\n",
    "xranks_wc = x_ranks[primary_index_wcontrast,:]\n",
    "yranks_wc = y_ranks[primary_index_wcontrast,:]\n",
    "\n",
    "# no contrast ranks\n",
    "dranks_nc = d_ranks[primary_index_no_contrast,:]\n",
    "hranks_nc = h_ranks[primary_index_no_contrast,:]\n",
    "xranks_nc = x_ranks[primary_index_no_contrast,:]\n",
    "yranks_nc = y_ranks[primary_index_no_contrast,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that carries out knn over n iterations and outputs:\n",
    "# average accuracy, all accuracies, average rocauc, all rocauc\n",
    "def Knn_accuracy(X, y, n_iter, test_ratio=0.25, nn = 5):\n",
    "    all_acc = [1000 for j in range(n_iter)]\n",
    "    all_roc = [1000 for j in range(n_iter)]\n",
    "    for i in range(n_iter):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            FDataGrid(X),\n",
    "            y.astype('int'),\n",
    "            test_size = test_ratio,\n",
    "            stratify=y,\n",
    "        )\n",
    "        knn = KNeighborsClassifier(n_neighbors=nn)\n",
    "        knn.fit(X_train, y_train)\n",
    "        all_acc[i] = knn.score(X_test, y_test)\n",
    "        pred = knn.predict(X_test)\n",
    "        all_roc[i] = roc_auc_score(y_test, pred)\n",
    "\n",
    "    acc = sum(all_acc)/n_iter\n",
    "    avg_roc = sum(all_roc)/n_iter\n",
    "    print(\"Average accuracy of Knn is \", acc, \"And average ROCAUC of Knn is \", avg_roc)\n",
    "    return acc, all_acc, avg_roc, all_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train knn classifier on data with contrast\n",
    "print(\"Train knn classifier on data with contrast \")\n",
    "\n",
    "print(\"performance of k-NN classifier trained on height-rips\")\n",
    "a,b,c,d = Knn_accuracy(hranks_wc, np.array(labels_wcontrast), 50, test_ratio=0.25, nn=5)\n",
    "print(\"accuracy variance \", statistics.stdev(b),\"roc variance \", statistics.stdev(d))\n",
    "\n",
    "\n",
    "print(\"performance of k-NN classifier trained on degree-rips\")\n",
    "a,b,c,d = Knn_accuracy(dranks_wc, np.array(labels_wcontrast), 50, test_ratio=0.25, nn=5)\n",
    "print(\"accuracy variance \", statistics.stdev(b),\"roc variance \", statistics.stdev(d))\n",
    "\n",
    "print(\"performance of k-NN classifier trained on y-rips\")\n",
    "a,b,c,d = Knn_accuracy(yranks_wc, np.array(labels_wcontrast), 50, test_ratio=0.25, nn=5)\n",
    "print(\"accuracy variance \", statistics.stdev(b),\"roc variance \", statistics.stdev(d))\n",
    "\n",
    "print(\"performance of k-NN classifier trained on x-rips\")\n",
    "a,b,c,d = Knn_accuracy(xranks_wc, np.array(labels_wcontrast), 50, test_ratio=0.25, nn=5)\n",
    "print(\"accuracy variance \", statistics.stdev(b),\"roc variance \", statistics.stdev(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train knn classifier on data without contrast \n",
    "print(\"Train knn classifier on data without contrast \")\n",
    "\n",
    "print(\"performance of k-NN classifier trained on height-rips\")\n",
    "a,b,c,d = Knn_accuracy(hranks_nc, np.array(labels_no_contrast), 50, test_ratio=0.25, nn=5)\n",
    "print(\"accuracy variance \", statistics.stdev(b),\"roc variance \", statistics.stdev(d))\n",
    "\n",
    "\n",
    "print(\"performance of k-NN classifier trained on degree-rips\")\n",
    "a,b,c,d = Knn_accuracy(dranks_nc, np.array(labels_no_contrast), 50, test_ratio=0.25, nn=5)\n",
    "print(\"accuracy variance \", statistics.stdev(b),\"roc variance \", statistics.stdev(d))\n",
    "\n",
    "print(\"performance of k-NN classifier trained on y-rips\")\n",
    "a,b,c,d = Knn_accuracy(yranks_nc, np.array(labels_no_contrast), 50, test_ratio=0.25, nn=5)\n",
    "print(\"accuracy variance \", statistics.stdev(b),\"roc variance \", statistics.stdev(d))\n",
    "\n",
    "print(\"performance of k-NN classifier trained on x-rips\")\n",
    "a,b,c,d = Knn_accuracy(xranks_nc, np.array(labels_no_contrast), 50, test_ratio=0.25, nn=5)\n",
    "print(\"accuracy variance \", statistics.stdev(b),\"roc variance \", statistics.stdev(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max depth classifier\n",
    "# define a function that carries out knn over n iterations and outputs the average aucroc, average accuracies, all aucroc and all accuracies\n",
    "def Maxdepth_acc_roc(X, y, n_iter, test_ratio=0.25, nn = 5):\n",
    "    all_roc = [1000 for j in range(n_iter)]\n",
    "    all_acc = [1000 for j in range(n_iter)]\n",
    "    for i in range(n_iter):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            FDataGrid(X),\n",
    "            y.astype('int'),\n",
    "            test_size = test_ratio,\n",
    "            stratify=y,\n",
    "        )\n",
    "        depth = MaximumDepthClassifier()\n",
    "        depth.fit(X_train, y_train)\n",
    "        pred = depth.predict(X_test)\n",
    "        all_roc[i] = roc_auc_score(y_test, pred)\n",
    "        all_acc[i] = depth.score(X_test, y_test)\n",
    "    avg = sum(all_roc)/n_iter\n",
    "    acc = sum(all_acc)/n_iter\n",
    "    print(\"Average aucroc of Max Depth classifier is \", avg)\n",
    "    print(\"Average accuracy of Max Depth classifier is \", acc)\n",
    "    return avg,acc, all_roc, all_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train MBD classifier on data with contrast \")\n",
    "\n",
    "print(\"performance of MBD classifier trained on height-rips\")\n",
    "a,b,c,d = Maxdepth_acc_roc(hranks_wc, np.array(labels_wcontrast), 50, test_ratio=0.25, nn=5)\n",
    "print(\"accuracy variance \", statistics.stdev(d),\"roc variance \", statistics.stdev(c))\n",
    "\n",
    "\n",
    "print(\"performance of MBD classifier trained on height-rips\")\n",
    "a,b,c,d = Maxdepth_acc_roc(dranks_wc, np.array(labels_wcontrast), 50, test_ratio=0.25, nn=5)\n",
    "print(\"accuracy variance \", statistics.stdev(d),\"roc variance \", statistics.stdev(c))\n",
    "\n",
    "print(\"performance of MBD classifier trained on y-rips\")\n",
    "a,b,c,d = Maxdepth_acc_roc(yranks_wc, np.array(labels_wcontrast), 50, test_ratio=0.25, nn=5)\n",
    "print(\"accuracy variance \", statistics.stdev(d),\"roc variance \", statistics.stdev(c))\n",
    "\n",
    "print(\"performance of MBD classifier trained on x-rips\")\n",
    "a,b,c,d = Maxdepth_acc_roc(xranks_wc, np.array(labels_wcontrast), 50, test_ratio=0.25, nn=5)\n",
    "print(\"accuracy variance \", statistics.stdev(d),\"roc variance \", statistics.stdev(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train MBD classifier on data without contrast \")\n",
    "\n",
    "print(\"performance of MBD classifier trained on height-rips\")\n",
    "a,b,c,d = Maxdepth_acc_roc(hranks_nc, np.array(labels_no_contrast), 50, test_ratio=0.25, nn=5)\n",
    "print(\"accuracy variance \", statistics.stdev(d),\"roc variance \", statistics.stdev(c))\n",
    "\n",
    "print(\"performance of MBD classifier trained on height-rips\")a,b,c,d = Maxdepth_acc_roc(dranks_nc, np.array(labels_no_contrast), 50, test_ratio=0.25, nn=5)\n",
    "print(\"accuracy variance \", statistics.stdev(d),\"roc variance \", statistics.stdev(c))\n",
    "\n",
    "print(\"performance of MBD classifier trained on y-rips\")\n",
    "a,b,c,d = Maxdepth_acc_roc(yranks_nc, np.array(labels_no_contrast), 50, test_ratio=0.25, nn=5)\n",
    "print(\"accuracy variance \", statistics.stdev(d),\"roc variance \", statistics.stdev(c))\n",
    "\n",
    "print(\"performance of MBD classifier trained on x-rips\")\n",
    "a,b,c,d = Maxdepth_acc_roc(xranks_nc, np.array(labels_no_contrast), 50, test_ratio=0.25, nn=5)\n",
    "print(\"accuracy variance \", statistics.stdev(d),\"roc variance \", statistics.stdev(c))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
